ğŸ§  DocDoctor

A full-stack RAG-powered web app to upload documents (PDF/DOCX/TXT) and ask natural language questions. Built with Django REST Framework, MySQL, ChromaDB, Next.js, and TailwindCSS.
ğŸš€ Features

    ğŸ“„ Upload & process documents (PDF, DOCX, TXT)

    ğŸ” Ask natural language questions

    ğŸ§  RAG pipeline (chunking, embeddings, similarity search, LLM answering)

    ğŸ“š Dashboard for managing documents

    ğŸ“¥ Upload page with drag-and-drop

    ğŸ¤– Uses LM Studio with llama-cpp for local LLM answering

    ğŸ³ Dockerized fullstack setup (MySQL + ChromaDB + frontend + backend)

ğŸ“¸ Screenshots

Add screenshots of your UI here (dashboard, upload, Q&A pages)
ğŸ§ª Sample Questions

Doc: "Intro to ML.pdf"
Q: What is the difference between supervised and unsupervised learning?
A: Supervised learning uses labeled data, while unsupervised does not. [Page 3]
ğŸ§± Tech Stack

    Frontend: Next.js, TailwindCSS

    Backend: Django REST Framework

    Vector DB: ChromaDB

    Auth: JWT, Supabase Auth (optional)

    LLM: LM Studio + llama-cpp

    DB: MySQL

    DevOps: Docker, Docker Compose

ğŸ› ï¸ Setup Instructions

git clone https://github.com/yourname/doc-intel-platform.git
cd doc-intel-platform

1. Start full app with Docker:

docker-compose up --build

Runs:

    Frontend at localhost:3000

    MySQL at localhost:3001

    ChromaDB at localhost:3002

    Backend at localhost:3003

2. LM Studio Setup (for LLM answers)

   Install LM Studio: https://lmstudio.ai

   Load a compatible model like Llama 3 Instruct

   Run server at localhost:1234

ğŸ“¬ API Reference
GET /api/documents

Returns list of uploaded documents
POST /api/upload

Upload and process a document
POST /api/query

Ask a question (params: doc_id, question, top_k)
ğŸ“‚ Folder Structure

/frontend â†’ Next.js app  
/backend â†’ Django REST API  
/docker â†’ docker-compose.yaml

ğŸ§¾ Requirements

requirements.txt (backend)
package.json (frontend)
.env.example

ğŸ“„ License

MIT
